{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import os.path, time\n",
    "import zipfile as zp\n",
    "import re\n",
    "import random\n",
    "from datetime import datetime, date\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as ax\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from statsmodels.base.model import LikelihoodModel\n",
    "\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import pearsonr\n",
    "import unicodedata\n",
    "#import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subfile_df():\n",
    "    path = \"/Users/zyy219/Documents/Risk_project/Data/Survey/\"\n",
    "    all_files = glob.glob(os.path.join(path, \"study_*_participant_responses.csv\"))\n",
    "    df_from_each_file = (pd.read_csv(f, sep=',') for f in all_files)\n",
    "    df_merged   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "    return df_merged\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_Dict():\n",
    "    sub_Dict = dict({99: ['797','806','809','826','843','845','855','856','857'], \n",
    "                 114: ['1031','1153','1154','1157','1174','1262','1264','1266',\n",
    "        '1364','1367','1379','1380','1381','1384','1435','1465','1467','1468','1489','1492','1493','1494','1495','1498','1519',\n",
    "        '1520','1527','1532','1536','1541','1721','1722','1737','1741','1788','1791','1810','1812','1833','1934'],\n",
    "        177:['2310','2316','2318','2323','2338','2339','2340','2348','2353','2356','2357','2358','2377',\n",
    "            '2378','2381','2383','2385','2386','2387','2388','2389','2390','2391','2394','2395','2396','2399',\n",
    "            '2401','2402','2404','2405','2407','2434','2444','2456',\n",
    "             '2433','2447','2477','2479','2489','2547','2548','2549','2553','2555','2558','2559','2578']}) \n",
    "    return sub_Dict\n",
    "\n",
    "def GetCohort(subID):\n",
    "    subDict = sub_Dict()\n",
    "    for key, value in subDict.items():\n",
    "        if subID in value:\n",
    "            return key\n",
    "        \n",
    "def subID_list():\n",
    "    subID = ['797','806','809','826','843','845','855','856','857','1031','1153','1154','1157','1174','1262','1264','1266',\n",
    "        '1364','1367','1379','1380','1381','1384','1435','1465','1467','1468','1489','1492','1493','1494','1495','1498','1519',\n",
    "        '1520','1527','1532','1536','1541','1721','1722','1737','1741','1788','1791','1810','1812','1833','1934',\n",
    "            '2310','2316','2318','2323','2338','2339','2340','2348','2353','2356','2357','2358','2377','2378',\n",
    "             '2381','2383','2385','2386','2387','2388','2389','2390','2391','2394','2395','2396','2399',\n",
    "             '2401','2402','2404','2405','2407','2434','2444','2456',\n",
    "            '2433','2447','2477','2479','2489','2547','2548','2549','2553','2555','2558','2559','2578']\n",
    "    return subID\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subID_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty, Risk (DOSPERT, IUS, LOT-R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dospert_domain_label(subID,Question):    \n",
    "    df = subfile_df()\n",
    "    S = [[10,'01'],[10,'08'],[20,'03'],[20,'06'],[30,'07'],[30,'10'],[40,'07'],[40,'08']]\n",
    "    R = [[10,'02'],[10,'04'],[20,'02'],[20,'04'],[20,'07'],[30,'04'],[40,'02'],[40,'03']]\n",
    "    F = [[10,'03'],[10,'05'],[10,'09'],[20,'05'],[20,'08'],[20,'09'],[30,'03'],[30,'06']]\n",
    "    H = [[10,'06'],[20,'10'],[30,'02'],[30,'05'],[40,'01'],[40,'04'],[40,'05'],[40,'06']]\n",
    "    E = [[10,'07'],[10,'10'],[20,'01'],[30,'01'],[30,'08'],[30,'09'],[40,'09'],[40,'10']]\n",
    "    if Question == 'Likelihood':\n",
    "        survey = ['DOSPERT-10', 'DOSPERT-20','DOSPERT-30','DOSPERT-40']\n",
    "    if Question == 'RP':\n",
    "        survey = ['DOSPERT-10-RP', 'DOSPERT-20-RP','DOSPERT-30-RP','DOSPERT-40-PP']\n",
    "    if Question == 'EB':\n",
    "        survey = ['DOSPERT-10-EB', 'DOSPERT-20-EB','DOSPERT-30-EB','DOSPERT-40-EB']\n",
    "    \n",
    "    subsetDataFrame =  df[df['survey_title'].isin(survey) & df['participant_id'].isin([subID])]\n",
    "    ser_title = subsetDataFrame['survey_title'].to_list()\n",
    "    q_title =  subsetDataFrame['question_title'].to_list()\n",
    "    n = [] #question_title\n",
    "    for s in range(len(q_title)):\n",
    "        if q_title[s][1] == '.':\n",
    "            n.append('0'+q_title[s][0])\n",
    "        else:\n",
    "            n.append(q_title[s][0:2])\n",
    "    answer_title = subsetDataFrame['answer_value'].to_list()\n",
    "    zip_title = []\n",
    "    domain_label = []\n",
    "    answer =[]\n",
    "    for i in range(len(ser_title)):\n",
    "        if Question == 'Likelihood':\n",
    "            zip_title.append([int(ser_title[i][-2:]),n[i]])\n",
    "        else:\n",
    "            zip_title.append([int(ser_title[i][-5:-3]),n[i]])\n",
    "        answer.append(int(answer_title[i][0]))\n",
    "        if zip_title[i] in S:\n",
    "            domain_label.append('S')\n",
    "        if zip_title[i] in R:\n",
    "            domain_label.append('R')\n",
    "        if zip_title[i] in F:\n",
    "            domain_label.append('F')\n",
    "        if zip_title[i] in H:\n",
    "            domain_label.append('H')\n",
    "        if zip_title[i] in E:\n",
    "            domain_label.append('E')\n",
    "    return domain_label, answer\n",
    "\n",
    "def dosert(subID,Question):\n",
    "\n",
    "    domain_label, answer = dospert_domain_label(subID,Question)\n",
    "\n",
    "    dospert = pd.DataFrame([domain_label,answer ]).T \n",
    "    dospert.columns = [\"domain_label\", \"answer\"]\n",
    "\n",
    "    dospert_domain = dospert.groupby(dospert.domain_label).sum()\n",
    "    dosert_score = dospert_domain.answer.to_list()\n",
    "    domain = dospert_domain.index.to_list()\n",
    "    return domain, dosert_score\n",
    "#40 is the highest likelihood of each domain\n",
    "\n",
    "\n",
    "def IUS_factor_label(subID):\n",
    "    df = subfile_df()\n",
    "    f1 =[[9,1], [9,2], [9,3], [9,9], [8,3], [8,4], [8,5], [8,6], [8,7], [8,8], [7,2], [7,4], [7,5], [7,6],[7,7]]\n",
    "    f2 = [[9,4], [9,5], [9,6], [9,7], [9,8], [8,1], [8,2], [8,9], [7,1], [7,3], [7,8], [7,9]]\n",
    "    survey = ['IUS-9', 'IUS-18','IUS-27']\n",
    "    subsetDataFrame =  df[df['survey_title'].isin(survey) & df['participant_id'].isin([subID])]\n",
    "    ser_title = subsetDataFrame['survey_title'].to_list()\n",
    "    q_title =  subsetDataFrame['question_title'].to_list()\n",
    "    answer_title = subsetDataFrame['answer_value'].to_list()\n",
    "    zip_title = []\n",
    "    domain_label = []\n",
    "    answer =[]\n",
    "    for i in range(len(ser_title)):\n",
    "        zip_title.append([int(ser_title[i][-1]),int(q_title[i][0])])\n",
    "        answer.append(int(answer_title[i][0]))\n",
    "        if zip_title[i] in f1:\n",
    "            domain_label.append('f1')\n",
    "        if zip_title[i] in f2:\n",
    "            domain_label.append('f2')\n",
    "       \n",
    "    return domain_label, answer\n",
    "\n",
    "def IUS_score(subID):\n",
    "    \n",
    "    domain_label, answer = IUS_factor_label(subID)\n",
    "    ius = pd.DataFrame([domain_label,answer ]).T \n",
    "    ius.columns = [\"domain_label\", \"answer\"]\n",
    "\n",
    "    ius_domain = ius.groupby(ius.domain_label).sum()\n",
    "    ius_score = ius_domain.answer.to_list()\n",
    "    domain = ius_domain.index.to_list()\n",
    "    return domain, ius_score\n",
    "\n",
    "def lot(subID):\n",
    "    df = subfile_df()\n",
    "    opt_des = [\"In uncertain times, I usually expect the best.\",\"I'm always optimistic about my future.\",\\\n",
    "           \"Overall, I expect more good things to happen to me than bad.\"]\n",
    "    pes_des = [\"If something can go wrong for me, it will.\",\"I hardly ever expect things to go my way.\",\\\n",
    "          \"I rarely count on good things happening to me.\"]\n",
    "    df_temp = df[df['survey_title'].isin(['LOT-R']) & df['participant_id'].isin([subID])]\n",
    "    question = df_temp['question_title'].to_list()\n",
    "    answer = df_temp['answer_value'].to_list()\n",
    "    opt_score = 0\n",
    "    pes_score = 0\n",
    "    for i in range(len(question)):\n",
    "        if question[i] in opt_des:\n",
    "        #print(answer[i])\n",
    "            if answer[i][0] == 'A':\n",
    "                opt_score+= 5\n",
    "            if answer[i][0] == 'B':\n",
    "                opt_score+= 4\n",
    "            if answer[i][0] == 'C':\n",
    "                opt_score+= 3\n",
    "            if answer[i][0] == 'D':\n",
    "                opt_score+= 2\n",
    "            if answer[i][0] == 'E':\n",
    "                opt_score+= 1\n",
    "        if question[i] in pes_des:\n",
    "        #print(answer[i])\n",
    "            if answer[i][0] == 'A':\n",
    "                pes_score+= 5\n",
    "            if answer[i][0] == 'B':\n",
    "                pes_score+= 4\n",
    "            if answer[i][0] == 'C':\n",
    "                pes_score+= 3\n",
    "            if answer[i][0] == 'D':\n",
    "                pes_score+= 2\n",
    "            if answer[i][0] == 'E':\n",
    "                pes_score+= 1\n",
    "    \n",
    "    return ['opt','pes'], [opt_score,pes_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impulsivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisbas_label(subID):\n",
    "    BAS =[[12,'03'], [12,'09'], [12,'12'], [24,'09'], [12,'05'], [12,'10'], [24,'03'], [24,'08'], \\\n",
    "      [12,'04'], [12,'07'], [24,'02'], [24,'06'], [12,'11']]\n",
    "    BIS = [[12,'02'], [12,'08'], [24,'01'], [24,'04'], [24,'07'], [24,'10'], [24,'12']]\n",
    "    \n",
    "    df = subfile_df()    \n",
    "    survey = ['BIS/BAS-12', 'BIS/BAS-24']\n",
    "    subsetDataFrame =  df[df['survey_title'].isin(survey) & df['participant_id'].isin([subID])]\n",
    "    ser_title = subsetDataFrame['survey_title'].to_list()\n",
    "    q_title =  subsetDataFrame['question_title'].to_list()\n",
    "    n = [] #question_title\n",
    "    for s in range(len(q_title)):\n",
    "        if q_title[s][1] == '.':\n",
    "            n.append('0'+q_title[s][0])\n",
    "        else:\n",
    "            n.append(q_title[s][0:2])\n",
    "            \n",
    "    answer_value = subsetDataFrame['answer_value'].to_list()\n",
    "    #print(answer_value)\n",
    "    zip_title = []\n",
    "    domain_label = []\n",
    "    answer =[]\n",
    "    for i in range(len(ser_title)):\n",
    "        zip_title.append([int(ser_title[i][-2:]),n[i]])\n",
    "        #print(zip_title[i])\n",
    "        if zip_title[i] == [12,'02']:\n",
    "            #print(i)\n",
    "            #print(answer_value[i][0])\n",
    "            if int(answer_value[i][0]) == 1:\n",
    "                answer.append(4)\n",
    "            if int(answer_value[i][0]) == 2:\n",
    "                answer.append(3)\n",
    "            if int(answer_value[i][0]) == 3:\n",
    "                answer.append(2)\n",
    "            if int(answer_value[i][0]) == 4:\n",
    "                answer.append(1)\n",
    "        elif zip_title[i] == [12,'08']:\n",
    "            #print(i)\n",
    "            #print(answer_value[i][0])\n",
    "            if int(answer_value[i][0]) == 1:\n",
    "                answer.append(4)\n",
    "            if int(answer_value[i][0]) == 2:\n",
    "                answer.append(3)\n",
    "            if int(answer_value[i][0]) == 3:\n",
    "                answer.append(2)\n",
    "            if int(answer_value[i][0]) == 4:\n",
    "                answer.append(1)\n",
    "        else:\n",
    "            answer.append(int(answer_value[i][0]))\n",
    "            #print(answer)\n",
    "        if zip_title[i] in BAS:\n",
    "            domain_label.append('bas')\n",
    "        if zip_title[i] in BIS:\n",
    "            domain_label.append('bis')\n",
    "        \n",
    "    return domain_label, answer\n",
    "\n",
    "def bisbas(subID):\n",
    "\n",
    "    domain_label, answer = bisbas_label(subID)\n",
    "\n",
    "    bisbas = pd.DataFrame([domain_label,answer ]).T \n",
    "    bisbas.columns = [\"domain_label\", \"answer\"]\n",
    "\n",
    "    bisbas_domain = bisbas.groupby(bisbas.domain_label).sum()\n",
    "    bisbas_score = bisbas_domain.answer.to_list()\n",
    "    domain = bisbas_domain.index.to_list()\n",
    "    return domain, bisbas_score\n",
    "\n",
    "def UPPS(subID):\n",
    "    \n",
    "    reverse = [[12,'02'],[12,'03'],[12,'05'],[12,'07'],[12,'08'],[12,'09'],[12,'10'],[12,'12'],\n",
    "          [24,'01'],[24,'03'],[24,'05'],[24,'06'],[24,'08'],[24,'10'],[24,'11'],\n",
    "          [36,'01'],[36,'02'],[36,'05'],[36,'06'],[36,'07'],[36,'10'],[36,'11'],[36,'12'],\n",
    "          [48,'03'],[48,'04'],[48,'05'],[48,'08'],[48,'09'],[48,'10'],[48,'11'],\n",
    "          [59,'01'],[59,'02'],[59,'03'],[59,'04'],[59,'06'],[59,'07'],[59,'08'],[59,'09'],[59,'10'],[59,'11']]\n",
    "     \n",
    "    df = subfile_df()\n",
    "    survey = ['UPPS-36', 'UPPS-48', 'UPPS-59', 'UPPS-24', 'UPPS-12']\n",
    "    subsetDataFrame =  df[df['survey_title'].isin(survey) & df['participant_id'].isin([subID])]\n",
    "    survey_title = subsetDataFrame['survey_title'].to_list()\n",
    "    question_title =  subsetDataFrame['question_title'].to_list()\n",
    "    n = [] #question_title\n",
    "    for s in range(len(question_title)):\n",
    "        if question_title[s][1] == '.':\n",
    "            n.append('0'+question_title[s][0])\n",
    "        else:\n",
    "            n.append(question_title[s][0:2])\n",
    "    answer_value = subsetDataFrame['answer_value'].to_list()\n",
    "    answer =[]\n",
    "    for i in range(len(survey_title)):\n",
    "    \n",
    "        zip_title = [int(survey_title[i][-2:]),n[i]]\n",
    "        if zip_title in reverse:\n",
    "        \n",
    "            if int(answer_value[i][0]) == 1:\n",
    "                answer.append(4)\n",
    "            \n",
    "            if int(answer_value[i][0]) == 2:\n",
    "                answer.append(3)\n",
    "            \n",
    "            if int(answer_value[i][0]) == 3:\n",
    "                answer.append(2)\n",
    "            \n",
    "            if int(answer_value[i][0]) == 4:\n",
    "                answer.append(1)       \n",
    "        else:\n",
    "            answer.append(int(answer_value[i][0]))\n",
    "    \n",
    "    result = sum(answer)\n",
    "    return result\n",
    "\n",
    "def bis11(subID):\n",
    "    df = subfile_df()\n",
    "    survey = ['BIS11-15', 'BIS11-30']\n",
    "    subsetDataFrame =  df[df['survey_title'].isin(survey) & df['participant_id'].isin([subID])]\n",
    "    question_title = subsetDataFrame['question_title'].to_list()\n",
    "    answer_value = subsetDataFrame['answer_value'].to_list()\n",
    "    reverse = ['12. I am a careful thinker.','1. I plan tasks carefully.','7. I plan trips well ahead of time.',\n",
    "              'I save regularly.','8.  I am self controlled.','15. I like to think about complex problems.',\n",
    "               '13. I plan for job security.','I concentrate easily.','15.  I am future oriented.',\n",
    "               '5. I am a steady thinker.','14. I like puzzles.','8. I can only think about one thing at a time.']\n",
    "    answer = []\n",
    "    for i in range(len(question_title)):\n",
    "        if  question_title[i] in reverse:\n",
    "\n",
    "            if int(answer_value[i][0]) == 1:\n",
    "                answer.append(4)\n",
    "\n",
    "            if int(answer_value[i][0]) == 2:\n",
    "                answer.append(3)\n",
    "\n",
    "            if int(answer_value[i][0]) == 3:\n",
    "                answer.append(2)\n",
    "\n",
    "            if int(answer_value[i][0]) == 4:\n",
    "                answer.append(1)       \n",
    "        else:\n",
    "            answer.append(int(answer_value[i][0]))\n",
    "    return sum(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anxiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phq(subID):\n",
    "    \n",
    "    df = subfile_df()\n",
    "    survey = ['PHQ8']\n",
    "    subsetDataFrame =  df[df['survey_title'].isin(survey) & df['participant_id'].isin([subID])]\n",
    "\n",
    "    answer_value = subsetDataFrame['answer_value'].to_list()\n",
    "    answer = []\n",
    "    for i in range(len(answer_value)):\n",
    "        answer.append(int(answer_value[i][0]))\n",
    "    #print(answer)\n",
    "    return sum(answer)\n",
    "\n",
    "def stai_s(subID):\n",
    "    df = subfile_df()\n",
    "    reverse = ['I feel calm.', 'I feel secure.', 'I feel at ease.','I feel satisfied.','I feel self-confident.','I am relaxed.'\n",
    "          'I feel content.','I feel steady','I feel pleasant.']\n",
    "    survey = ['STAI-State']\n",
    "    subsetDataFrame =  df[df['survey_title'].isin(survey) & df['participant_id'].isin([subID])]\n",
    "\n",
    "    question_title =  subsetDataFrame['question_title'].to_list()\n",
    "    answer_value = subsetDataFrame['answer_value'].to_list()\n",
    "\n",
    "    answer =[]\n",
    "    for i in range(len(question_title)):\n",
    "\n",
    "        if question_title[i] in reverse:\n",
    "        \n",
    "            if int(answer_value[i][0]) == 1:\n",
    "                answer.append(4)\n",
    "            \n",
    "            if int(answer_value[i][0]) == 2:\n",
    "                answer.append(3)\n",
    "\n",
    "            if int(answer_value[i][0]) == 3:\n",
    "                answer.append(2)\n",
    "\n",
    "            if int(answer_value[i][0]) == 4:\n",
    "                answer.append(1)       \n",
    "        else:\n",
    "            answer.append(int(answer_value[i][0]))\n",
    "\n",
    "    result = sum(answer)\n",
    "    return result\n",
    "\n",
    "def stai_t(subID):\n",
    "    df = subfile_df()\n",
    "    survey = ['STAI-Trait']\n",
    "    subsetDataFrame =  df[df['survey_title'].isin(survey) & df['participant_id'].isin([subID])]\n",
    "    reverse = ['I feel pleasant','I feel satisfied with myself','I feel rested','I am \"calm, cool, and collected\"',\n",
    "               'I am happy','I feel secure','I make decisions easily','I am content','I am a steady person']\n",
    "    question_title =  subsetDataFrame['question_title'].to_list()\n",
    "    answer_value = subsetDataFrame['answer_value'].to_list()\n",
    "\n",
    "    answer =[]\n",
    "    for i in range(len(question_title)):\n",
    "\n",
    "        if question_title[i] in reverse:\n",
    "\n",
    "            if int(answer_value[i][0]) == 1:\n",
    "                answer.append(4)\n",
    "\n",
    "            if int(answer_value[i][0]) == 2:\n",
    "                answer.append(3)\n",
    "\n",
    "            if int(answer_value[i][0]) == 3:\n",
    "                answer.append(2)\n",
    "\n",
    "            if int(answer_value[i][0]) == 4:\n",
    "                answer.append(1)       \n",
    "        else:\n",
    "            answer.append(int(answer_value[i][0]))\n",
    "\n",
    "    result = sum(answer)\n",
    "    return result\n",
    "\n",
    "def BSI(subID):\n",
    "    df = subfile_df()\n",
    "\n",
    "    somatization = ['Faintness or dizziness','Pains in the heart or chest','Nausea or upset stomach',\n",
    "            'Trouble getting your breath','Hot or cold spells.','Numbness or tingling in parts of your body',\n",
    "           'Feeling weak in parts of your body']\n",
    "    obssession = ['Trouble remembering things','Feeling blocked in getting things done',\n",
    "               'Having to check and double check what you do','Difficulty making decisions','Your mind going blank',\n",
    "              'Trouble concertrating']\n",
    "    interpersonal = ['Your feelings being easily hurt','Feeling that people are unfriendly or dislike you',\n",
    "                    'Feeling inferior to others']\n",
    "\n",
    "    anxiety = ['Nervousness or shakiness inside','Suddenly scared for no reason','Feeling fearful',\n",
    "               'Feeling tense or keyed up','Spells of terror or panic','Feeling so restless you couldn’t sit still']\n",
    "\n",
    "    hosbility = ['Feeling easily annoyed or irritated','Temper outbursts that you could not control',\n",
    "                'Having urges to beat, injure, or harm someone','Having urges to break or smash things',\n",
    "                'Getting into frequent arguments']\n",
    "\n",
    "    phobic = ['Feeling afraid in open spaces','Feeling afraid to travel on buses, subways, or trains',\n",
    "             'Having to avoid certain things, places, or activities because they frighten you','Feeling uneasy in crowds',\n",
    "             'Feeling nervous when you are left alone']\n",
    "\n",
    "    paranoid = ['Feeling others are to blame for most of your troubles','Feeling that most people cannot be trusted',\n",
    "               'Feeling that you are watched or talked about by others',\n",
    "                'Others not giving you proper credit for your achievements','Feeling that people will take advantage of you if you let them']\n",
    "\n",
    "    psychoticism = ['The idea that someone else can control your thoughts','Feeling lonely even when you are with people',\n",
    "                   'The idea that you should be punished for your sins','Never feeling close to another person',\n",
    "                   'The idea that something is wrong with your mind']\n",
    "    appetite = ['Poor appetite']\n",
    "    sleep = ['Trouble falling asleep']\n",
    "    #death = ['Thoughts of death or dying']\n",
    "    guilt = ['Feeling of guilt']\n",
    "\n",
    "    survey = ['BSI-9', 'BSI-20', 'BSI-36', 'BSI-45', 'BSI-53']\n",
    "    subsetDataFrame =  df[df['survey_title'].isin(survey) & df['participant_id'].isin([subID])]\n",
    "    survey_title = subsetDataFrame['survey_title'].to_list()\n",
    "    question_title =  subsetDataFrame['question_title'].to_list()\n",
    "    answer_value = subsetDataFrame['answer_value'].to_list()\n",
    "    for i in range(len(answer_value)):\n",
    "        if answer_value[i] == 'Refused':\n",
    "            answer_value[i] = '0'\n",
    "    answer =[]\n",
    "    question = []\n",
    "    for i in range(len(question_title)):\n",
    "        new_str = unicodedata.normalize(\"NFKD\", question_title[i])\n",
    "        question.append(new_str.strip())\n",
    "    som = []\n",
    "    obs = []\n",
    "    inte = []\n",
    "    anx = []\n",
    "    hos = []\n",
    "    pho = []\n",
    "    par = []\n",
    "    psy = []\n",
    "    ape = []\n",
    "    slp = []\n",
    "    gui = []\n",
    "\n",
    "    for i in range(len(question_title)):\n",
    "        if question[i][3:] in somatization:\n",
    "            som.append(int(answer_value[i][0]))\n",
    "        if question[i][4:] in somatization:\n",
    "            som.append(int(answer_value[i][0]))\n",
    "\n",
    "        if question[i][3:] in obssession:\n",
    "            obs.append(int(answer_value[i][0]))\n",
    "        if question[i][4:] in obssession:\n",
    "            obs.append(int(answer_value[i][0]))\n",
    "\n",
    "        if question[i][3:] in interpersonal:\n",
    "            inte.append(int(answer_value[i][0]))\n",
    "        if question[i][4:] in interpersonal:\n",
    "            inte.append(int(answer_value[i][0]))\n",
    "\n",
    "        if question[i][3:] in anxiety:\n",
    "            anx.append(int(answer_value[i][0]))\n",
    "        if question[i][4:] in anxiety:\n",
    "            anx.append(int(answer_value[i][0]))\n",
    "\n",
    "        if question[i][3:] in hosbility:\n",
    "            hos.append(int(answer_value[i][0]))\n",
    "        if question[i][4:] in hosbility:\n",
    "            hos.append(int(answer_value[i][0]))\n",
    "\n",
    "        if question[i][3:] in phobic:\n",
    "            pho.append(int(answer_value[i][0]))\n",
    "        if question[i][4:] in phobic:\n",
    "            pho.append(int(answer_value[i][0]))\n",
    "\n",
    "        if question[i][3:] in paranoid:\n",
    "            par.append(int(answer_value[i][0]))\n",
    "        if question[i][4:] in paranoid:\n",
    "            par.append(int(answer_value[i][0]))\n",
    "\n",
    "        if question[i][3:] in psychoticism:\n",
    "            psy.append(int(answer_value[i][0]))\n",
    "        if question[i][4:] in psychoticism:\n",
    "            psy.append(int(answer_value[i][0]))\n",
    "            \n",
    "        if question[i][3:] in appetite:\n",
    "            ape.append(int(answer_value[i][0]))\n",
    "        if question[i][4:] in appetite:\n",
    "            ape.append(int(answer_value[i][0]))\n",
    "            \n",
    "        if question[i][3:] in sleep:\n",
    "            slp.append(int(answer_value[i][0]))\n",
    "        if question[i][4:] in sleep:\n",
    "            slp.append(int(answer_value[i][0])) \n",
    "            \n",
    "        if question[i][3:] in guilt:\n",
    "            gui.append(int(answer_value[i][0]))\n",
    "        if question[i][4:] in guilt:\n",
    "            gui.append(int(answer_value[i][0]))  \n",
    "            \n",
    "            \n",
    "    psycharity = [sum(som), sum(obs), sum(inte), sum(anx), sum(hos), sum(pho), sum(par), sum(psy), \n",
    "                  sum(ape), sum(slp), sum(gui)]\n",
    "    return psycharity\n",
    "\n",
    "def BAI(subID):\n",
    "    df = subfile_df()\n",
    "    survey = ['BAI']\n",
    "    subsetDataFrame =  df[df['survey_title'].isin(survey) & df['participant_id'].isin([subID])]\n",
    "    \n",
    "    question_title =  subsetDataFrame['question_title'].to_list()\n",
    "    answer_value = subsetDataFrame['answer_value'].to_list()\n",
    "\n",
    "    answer =[]\n",
    "    for i in range(len(question_title)):\n",
    "        answer.append(int(answer_value[i][0]))\n",
    "    result = sum(answer)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cognitvie task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Raven_score(subID):\n",
    "    sub = int(subID)\n",
    "    Raven= pd.read_csv(\"/Users/zyy219/Documents/Risk_project/Data/Cognition/Raven.csv\").set_index(\"subID\").T.reset_index()\n",
    "    Answer = pd.read_csv(\"/Users/zyy219/Documents/Risk_project/Data/Cognition/Raven_Answer.txt\", sep=\",\", header=None)\n",
    "    Answer = Answer.T\n",
    "    Answer.columns = [\"Answer\"]\n",
    "    Raven[\"Answer\"] = Answer\n",
    "    Raven['Answer_copy'] = Raven['Answer']\n",
    "    Raven1 = Raven.apply(lambda x: np.where(x == Raven[\"Answer_copy\"], 1, 0), axis = 0).reset_index().drop([\"Answer_copy\"], axis = 1)\n",
    "    final = Raven1.drop(columns = [\"level_0\", \"index\",\"Answer\"])\n",
    "    namelist = final.columns\n",
    "    if sub in namelist:\n",
    "        iq = final[sub].sum()\n",
    "        if np.shape(iq) != ():\n",
    "            iq = max(iq)\n",
    "    else:\n",
    "        iq = float(\"NaN\")\n",
    "    return iq\n",
    "\n",
    "\n",
    "def numeracy(subID):\n",
    "    Numeracy = pd.read_csv(\"/Users/zyy219/Documents/Risk_project/Data/Cognition/Numeracy.csv\")\n",
    "    values = [0, 1]\n",
    "    \n",
    "    Numeracy[\"Q1\"][1: ] = Numeracy[\"Q1\"][1: ].apply(lambda x: re.sub(r'[a-z$,]', '', str(x)))\n",
    "    correctQ1 = [(Numeracy[\"Q1\"] != \"0.05\"),(Numeracy[\"Q1\"] == \"0.05\")]\n",
    "    Numeracy[\"Correct%Q1\"] = np.select(correctQ1, values)\n",
    "\n",
    "    Numeracy[\"Q2\"][1: ] = Numeracy[\"Q2\"][1: ].apply(lambda x: re.sub(r'[a-z,]', '', str(x)))\n",
    "    correctQ2 = [(Numeracy[\"Q2\"] != \"5\"),(Numeracy[\"Q2\"] == \"5\")]\n",
    "    Numeracy[\"Correct%Q2\"] = np.select(correctQ2, values)\n",
    "\n",
    "    Numeracy[\"Q3\"][1: ] = Numeracy[\"Q3\"][1: ].apply(lambda x: re.sub(r'[a-z,]', '', str(x)))\n",
    "    correctQ3 = [(Numeracy[\"Q3\"] != \"47\"), (Numeracy[\"Q3\"] == \"47\")]\n",
    "    Numeracy[\"Correct%Q3\"] = np.select(correctQ3, values)\n",
    "\n",
    "    Numeracy[\"Q4\"][1: ] = Numeracy[\"Q4\"][1: ].apply(lambda x: re.sub(r'[a-z$,]', '', str(x)))\n",
    "    correctQ4 = [(Numeracy[\"Q4\"] != \"150\"),(Numeracy[\"Q4\"] == \"150\")]\n",
    "    Numeracy[\"Correct%Q4\"] = np.select(correctQ4, values)\n",
    "\n",
    "    Numeracy[\"Q5\"][1: ] = Numeracy[\"Q5\"][1: ].apply(lambda x: re.sub(r'[a-z,%]', '', str(x)))\n",
    "    correctQ5 = [(Numeracy[\"Q5\"] != \"1\"),(Numeracy[\"Q5\"] == \"1\")]\n",
    "    Numeracy[\"Correct%Q5\"] = np.select(correctQ5, values)\n",
    "    \n",
    "    Numeracy[\"Q6\"][1: ] = Numeracy[\"Q6\"][1: ].apply(lambda x: re.sub(r'[a-z,%]', '', str(x)))\n",
    "    correctQ6 = [(Numeracy[\"Q6\"] != \"2. Ten percent (10%)\"), (Numeracy[\"Q6\"] == \"2. Ten percent (10%)\")]\n",
    "    Numeracy[\"Correct%Q6\"] = np.select(correctQ6, values)\n",
    "    \n",
    "    Numeracy[\"Q7\"][1: ] = Numeracy[\"Q7\"][1: ].apply(lambda x: re.sub(r'[a-z,%]', '', str(x)))\n",
    "    correctQ7 = [(Numeracy[\"Q7\"] != \"3. Something that happens 1 in 10 times\"),\n",
    "            (Numeracy[\"Q7\"] == \"3. Something that happens 1 in 10 times\")]\n",
    "    Numeracy[\"Correct%Q7\"] = np.select(correctQ7, values)\n",
    "\n",
    "    Numeracy[\"Q8\"][1: ] = Numeracy[\"Q8\"][1: ].apply(lambda x: re.sub(r'[a-z$,]', '', str(x)))\n",
    "    correctQ8 = [(Numeracy[\"Q8\"] == \"400000\"), \n",
    "                 (Numeracy[\"Q8\"] != \"400000\")]\n",
    "    Numeracy[\"Correct%Q8\"] = np.select(correctQ8, values)\n",
    "\n",
    "    Numeracy[\"Q9\"][1: ] = Numeracy[\"Q9\"][1: ].apply(lambda x: re.sub(r'[a-z$,]', '', str(x)))\n",
    "    correctQ9 = [(Numeracy[\"Q9\"] == \"242\"), (Numeracy[\"Q9\"] != \"242\")]\n",
    "    Numeracy[\"Correct%Q9\"] = np.select(correctQ9, values)\n",
    "    \n",
    "    Numeracy[\"NumeracyFinal\"] = Numeracy[\"Correct%Q1\"] + Numeracy[\"Correct%Q2\"] + Numeracy[\"Correct%Q3\"] + Numeracy[\"Correct%Q4\"] + Numeracy[\"Correct%Q5\"] + Numeracy[\"Correct%Q6\"] + Numeracy[\"Correct%Q7\"] + Numeracy[\"Correct%Q8\"] + Numeracy[\"Correct%Q9\"]\n",
    "    df = Numeracy[['Q15', 'NumeracyFinal']][1:]\n",
    "    sublist = Numeracy['Q15'][1:].tolist()\n",
    "    if subID in sublist:\n",
    "        score = df['NumeracyFinal'][df['Q15'] == subID].tolist()[0]\n",
    "    else:\n",
    "        score = float('NaN')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_score(sub_id):\n",
    "    positive = ['Happy', 'Enjoying myself', 'Warm/ friendly']\n",
    "    negative =['4. Depressed/ blue', 'Angry / hostile', 'Criticized/put down \\xa0\\xa0\\xa0', 'Worried/ anxious\\xa0', 'Frustrated/annoyed', \\\n",
    "           'Hassled / pushed around']\n",
    "    survey = ['DRM']\n",
    "    df = subfile_df()\n",
    "    subsetDataFrame =  df[df['survey_title'].isin(survey) & df['participant_id'].isin([sub_id])]\n",
    "    time = subsetDataFrame['start_by'].unique()\n",
    "    \n",
    "    p_score = []\n",
    "    n_score = []\n",
    "\n",
    "    for t in range(len(time)):\n",
    "        df_temp = subsetDataFrame[subsetDataFrame['start_by'].isin([time[t]])]\n",
    "        q_title =  df_temp['question_title'].to_list()\n",
    "    \n",
    "        positive_score = 0\n",
    "        negative_score = 0\n",
    "        answer_title = df_temp['answer_value'].to_list()\n",
    "    \n",
    "        for i in range(len(q_title)):\n",
    "            \n",
    "            if q_title[i] in positive:\n",
    "                positive_score += int(answer_title[i][0]) \n",
    "            \n",
    "            if q_title[i] in negative:\n",
    "                negative_score += int(answer_title[i][0])   \n",
    "        \n",
    "        p_score.append(positive_score)\n",
    "        n_score.append(negative_score)\n",
    "        \n",
    "    ps = np.round(np.array(p_score)/3,2)\n",
    "    ns = np.round(np.array(n_score)/6,2)\n",
    "    return ps, ns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subID = sub_Dict().get(99)+sub_Dict().get(114)\n",
    "subNo = len(subID)\n",
    "\n",
    "positive_score = np.empty([subNo, 11])\n",
    "negative_score = np.empty([subNo, 11])\n",
    "\n",
    "for i in range(len(subID)):\n",
    "    ps, ns = emotion_score(subID[i])\n",
    "    #print(subID[i])\n",
    "    if subID[i] == '1262':\n",
    "        ps = np.delete(ps, [1])\n",
    "        ns = np.delete(ns, [1])\n",
    "    positive_score[i][:] = ps\n",
    "    negative_score[i][:] = ns\n",
    "\n",
    "\n",
    "w1 = positive_score[:,0]\n",
    "w2 = np.sum(positive_score[:,1:3],axis = 1)/2\n",
    "w7 = np.sum(positive_score[:,7:9],axis = 1)/2\n",
    "w8 = np.sum(positive_score[:,9:11],axis = 1)/2\n",
    "\n",
    "positive = np.empty([subNo,8])\n",
    "\n",
    "positive[:,0] = w1\n",
    "positive[:,1] = w2\n",
    "positive[:,2:6] = positive_score[:,2:6]\n",
    "positive[:,6] = w7\n",
    "positive[:,7] = w8\n",
    "\n",
    "#negative score\n",
    "nw1 = negative_score[:,0]\n",
    "nw2 = np.sum(negative_score[:,1:3],axis = 1)/2\n",
    "nw7 = np.sum(negative_score[:,7:9],axis = 1)/2\n",
    "nw8 = np.sum(negative_score[:,9:11],axis = 1)/2\n",
    "\n",
    "negative = np.empty([subNo,8])\n",
    "\n",
    "negative[:,0] = nw1\n",
    "negative[:,1] = nw2\n",
    "negative[:,2:6] = negative_score[:,2:6]\n",
    "negative[:,6] = nw7\n",
    "negative[:,7] = nw8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_positive = np.mean(positive,axis = 1).reshape([subNo,1])\n",
    "mean_negative = np.mean(negative, axis = 1).reshape([subNo,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort3 = sub_Dict().get(177)\n",
    "positive_score_c3 = np.empty([len(cohort3), 16])\n",
    "negative_score_c3 = np.empty([len(cohort3), 16])\n",
    "\n",
    "for i in range(len(cohort3)):\n",
    "    ps, ns = emotion_score(cohort3[i])\n",
    "    positive_score_c3[i][:] = ps\n",
    "    negative_score_c3[i][:] = ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_c3 = np.empty([len(cohort3),8])\n",
    "negative_c3 = np.empty([len(cohort3),8])\n",
    "\n",
    "for i in range(8):\n",
    "    positive_c3[:,i] = np.mean(positive_score_c3[:,(2*i):2*(i+1)],axis = 1)\n",
    "    negative_c3[:,i] = np.mean(negative_score_c3[:,(2*i):2*(i+1)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_positive_c3 = np.mean(positive_c3,axis = 1).reshape([len(cohort3),1])\n",
    "mean_negative_c3 = np.mean(negative_c3, axis = 1).reshape([len(cohort3),1])\n",
    "\n",
    "positive_all = np.concatenate((mean_positive,mean_positive_c3),axis = 0)\n",
    "negative_all = np.concatenate((mean_negative,mean_negative_c3),axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty Scale - IUS, LOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subID = subID_list()\n",
    "variable_NO = 5\n",
    "trait = np.empty([len(subID),variable_NO])\n",
    "for i in range(len(subID)):\n",
    "    \n",
    "    ius_label, ius_score = IUS_score(subID[i])\n",
    "    #print(ius_score)\n",
    "    lot_label, lot_score = lot(subID[i])\n",
    "    \n",
    "    \n",
    "    trait[i][0] = np.array(np.sum(ius_score))\n",
    "    trait[i][1:3] = np.array(lot_score)\n",
    "    trait[i][3] = positive_all[i]\n",
    "    trait[i][4] = negative_all[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOSPERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb = np.empty([len(subID),5])\n",
    "li = np.empty([len(subID),5])\n",
    "rp = np.empty([len(subID),5])\n",
    "for i in range(len(subID)):\n",
    "    dosert_label, dosert_score_EB = dosert(subID[i],'EB')\n",
    "    eb[i,:] = dosert_score_EB\n",
    "    desert_label, dosert_score_LI = dosert(subID[i],'Likelihood')\n",
    "    li[i,:] = dosert_score_LI\n",
    "    desert_label, dosert_score_RP = dosert(subID[i],'RP')\n",
    "    rp[i,:] = dosert_score_RP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impulsivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait_imp = np.empty([len(subID),4])\n",
    "for i in range(len(subID)):\n",
    "    basbis_label, basbis_score = bisbas(subID[i])\n",
    "    bis11_score = bis11(subID[i])\n",
    "    upps_score = UPPS(subID[i])\n",
    "    trait_imp[i][0:2] = np.array(basbis_score)\n",
    "    trait_imp[i][2] = np.array(bis11_score)\n",
    "    trait_imp[i][3] = np.array(upps_score)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c4e4e51bc4d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstai_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubID\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m73\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-8e77516c2618>\u001b[0m in \u001b[0;36mstai_s\u001b[0;34m(subID)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'y'"
     ]
    }
   ],
   "source": [
    "stai_s(subID[73])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mental Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_variable_No = 5\n",
    "subID = subID_list()\n",
    "trait_mental = np.empty([len(subID),mental_variable_No])\n",
    "for i in range(len(subID)):\n",
    "    if GetCohort(subID[i]) !=177:\n",
    "        phq_score = phq(subID[i]) #past 2 weeks, 8 questions, 1-4\n",
    "        stais_score = stai_s(subID[i])\n",
    "    else:\n",
    "        phq_score = phq(subID[i])/4\n",
    "        #print(i)\n",
    "        stais_score = stai_s(subID[i])/4 #20 question, 1-4\n",
    "    \n",
    "    stait_score = stai_t(subID[i])\n",
    "    BAI_score = BAI(subID[i])\n",
    "    BSI_score = BSI(subID[i])\n",
    "    trait_mental[i][0] = np.array(phq_score)\n",
    "    trait_mental[i][1] = np.array(stais_score)\n",
    "    trait_mental[i][2] = np.array(stait_score)\n",
    "    trait_mental[i][3] = np.array(BAI_score)\n",
    "    trait_mental[i][4] = np.array(np.sum(BSI_score))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 29)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = np.concatenate((eb,li,rp,trait,trait_imp, trait_mental), axis=1)\n",
    "label = ['E_EB','F_EB','S_EB','R_EB','S_EB','E_LI','F_LI','S_LI','R_LI','S_LI','E_RP','F_RP','S_RP','R_RP','S_RP',\n",
    "        'IUS','lot_pos','lot_neg','drm_pos','drm_neg','BAS','BIS','BIS11','UPPS',\n",
    "         'phq','stais','stait','bai','bsi']\n",
    "np.shape(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = pd.DataFrame(data=var, index = subID_list(), columns=label)\n",
    "variables\n",
    "variables.to_csv(\"/Users/zyy219/Documents/Risk_project/Data/Independent_variable.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
